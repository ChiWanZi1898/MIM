\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{zhang2017deep}
\citation{shi2015convolutional,wang2017predrnn}
\citation{shi2015convolutional}
\citation{wang2017predrnn}
\citation{hochreiter1997long}
\citation{wang2017predrnn}
\citation{percival1993spectral}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\newlabel{sec:Introduction}{{1}{1}{\hskip -1em.~Introduction}{section.1}{}}
\@writefile{brf}{\backcite{zhang2017deep}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{shi2015convolutional}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{shi2015convolutional}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{hochreiter1997long}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{1}{1}{section.1}}}
\@writefile{brf}{\backcite{percival1993spectral}{{1}{1}{section.1}}}
\citation{krizhevsky2012imagenet}
\citation{Sutskever2014Sequence}
\citation{Ranzato2014Video}
\citation{srivastava2015unsupervised}
\citation{shi2015convolutional}
\citation{Finn2016Unsupervised}
\citation{Villegas2017Decomposing}
\citation{patraucean2015spatio}
\citation{Kalchbrenner2016Video}
\citation{van2016conditional}
\citation{wang2017predrnn}
\citation{Mathieu2015Deep}
\citation{Goodfellow2014Generative,Denton2015Deep}
\citation{vondrick2016generating}
\citation{kingma2013auto}
\citation{lee2018stochastic}
\citation{denton2018stochastic}
\citation{wang2017predrnn}
\citation{shi2015convolutional}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{2}{section.2}}
\newlabel{sec:Related}{{2}{2}{\hskip -1em.~Related Work}{section.2}{}}
\@writefile{brf}{\backcite{krizhevsky2012imagenet}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Sutskever2014Sequence}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Ranzato2014Video}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{srivastava2015unsupervised}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{shi2015convolutional}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Finn2016Unsupervised}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Villegas2017Decomposing}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{patraucean2015spatio}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Kalchbrenner2016Video}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{van2016conditional}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Mathieu2015Deep}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Goodfellow2014Generative}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{Denton2015Deep}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{vondrick2016generating}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{kingma2013auto}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{lee2018stochastic}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{denton2018stochastic}{{2}{2}{section.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Preliminaries}{2}{section.3}}
\newlabel{sec:Preliminaries}{{3}{2}{\hskip -1em.~Preliminaries}{section.3}{}}
\@writefile{brf}{\backcite{wang2017predrnn}{{2}{3}{section.3}}}
\@writefile{brf}{\backcite{shi2015convolutional}{{2}{3}{section.3}}}
\newlabel{equ:stlstm}{{1}{2}{\hskip -1em.~Preliminaries}{equation.3.1}{}}
\citation{percival1993spectral}
\citation{wang2017predrnn}
\citation{wang2017predrnn}
\citation{wang2017predrnn}
\citation{wang2017predrnn}
\citation{percival1993spectral}
\@writefile{brf}{\backcite{hochreiter1997long}{{3}{3}{equation.3.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Methods}{3}{section.4}}
\newlabel{sec:Methods}{{4}{3}{\hskip -1em.~Methods}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Differential Recurrent Neural Network}{3}{subsection.4.1}}
\@writefile{brf}{\backcite{percival1993spectral}{{3}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{3}{4.1}{figure.caption.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The structure of DRNN with $4$ layers. The vertical (gray) arrows denote the zigzag information flows of the spatiotemporal memory $\mathcal  {M}$ designed in PredRNN; the diagonal (orange) arrows are added to further deliver the hidden states to generate differential features $\mathcal  {D}$; and the horizontal (blue) arrows are modified to deliver the temporal memory $\mathcal  {C}$ designed in LSTM, as well as the stationary memory $\mathcal  {S}$ and non-stationary memory $\mathcal  {N}$ designed in the MIM. \relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:structure}{{1}{3}{The structure of DRNN with $4$ layers. The vertical (gray) arrows denote the zigzag information flows of the spatiotemporal memory $\mathcal {M}$ designed in PredRNN; the diagonal (orange) arrows are added to further deliver the hidden states to generate differential features $\mathcal {D}$; and the horizontal (blue) arrows are modified to deliver the temporal memory $\mathcal {C}$ designed in LSTM, as well as the stationary memory $\mathcal {S}$ and non-stationary memory $\mathcal {N}$ designed in the MIM. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Memory In Memory}{3}{subsection.4.2}}
\@writefile{brf}{\backcite{wang2017predrnn}{{3}{4.2}{figure.caption.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The ST-LSTM block \citep  {wang2017predrnn} in the left plot and the proposed Memory In Memory (MIM) block in the right plot. MIM is designed to introduce two recurrent units (yellow squares) to replace the forget gate (dashed box) in ST-LSTM. MIM-S denotes the stationary unit and MIM-N denotes the non-stationary unit. Note that the MIM block cannot be used in the first layer so the input $\mathcal  {X}_t$ is replaced by $\mathcal  {H}_t^{l-1}$.\relax }}{4}{figure.caption.2}}
\@writefile{brf}{\backcite{wang2017predrnn}{{4}{2}{figure.caption.2}}}
\newlabel{fig:node}{{2}{4}{The ST-LSTM block \citep {wang2017predrnn} in the left plot and the proposed Memory In Memory (MIM) block in the right plot. MIM is designed to introduce two recurrent units (yellow squares) to replace the forget gate (dashed box) in ST-LSTM. MIM-S denotes the stationary unit and MIM-N denotes the non-stationary unit. Note that the MIM block cannot be used in the first layer so the input $\mathcal {X}_t$ is replaced by $\mathcal {H}_t^{l-1}$.\relax }{figure.caption.2}{}}
\@writefile{brf}{\backcite{percival1993spectral}{{4}{4.2}{figure.caption.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Non-stationary unit (MIM-N) and stationary unit (MIM-S), which are organized in a cascade structure in the MIM block. Note that non-stationary variation is modeled by sequence differencing.\relax }}{4}{figure.caption.3}}
\newlabel{fig:subunits}{{3}{4}{Non-stationary unit (MIM-N) and stationary unit (MIM-S), which are organized in a cascade structure in the MIM block. Note that non-stationary variation is modeled by sequence differencing.\relax }{figure.caption.3}{}}
\newlabel{equ:MIM}{{2}{4}{\hskip -1em.~Memory In Memory}{equation.4.2}{}}
\citation{Kingma2014Adam}
\citation{Ba2016Layer}
\citation{ioffe2015batch}
\citation{Abadi2016TensorFlow}
\citation{shi2015convolutional}
\citation{oliu2017folded}
\citation{Sutskever2014Sequence,Cho2014On}
\citation{Kalchbrenner2016Video}
\citation{srivastava2015unsupervised}
\citation{wang2017predrnn}
\citation{bengio2015scheduled}
\citation{Wang2004Image}
\citation{srivastava2015unsupervised}
\citation{shi2017deep}
\citation{Finn2016Unsupervised}
\citation{de2016dynamic}
\newlabel{equ:stationary}{{3}{5}{\hskip -1em.~Memory In Memory}{equation.4.3}{}}
\newlabel{equ:non-stationary}{{4}{5}{\hskip -1em.~Memory In Memory}{equation.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiments}{5}{section.5}}
\newlabel{sec:Experiments}{{5}{5}{\hskip -1em.~Experiments}{section.5}{}}
\@writefile{brf}{\backcite{Kingma2014Adam}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{Ba2016Layer}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{ioffe2015batch}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{Abadi2016TensorFlow}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{shi2015convolutional}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{oliu2017folded}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{Sutskever2014Sequence}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{Cho2014On}{{5}{5}{section.5}}}
\@writefile{brf}{\backcite{Kalchbrenner2016Video}{{5}{5}{section.5}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Moving MNIST Dataset}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {paragraph}{Implementation}{5}{section*.4}}
\@writefile{brf}{\backcite{srivastava2015unsupervised}{{5}{5.1}{section*.4}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{5}{5.1}{section*.4}}}
\@writefile{brf}{\backcite{bengio2015scheduled}{{5}{5.1}{section*.4}}}
\@writefile{toc}{\contentsline {paragraph}{Results}{5}{section*.7}}
\@writefile{brf}{\backcite{Wang2004Image}{{5}{5.1}{section*.7}}}
\@writefile{brf}{\backcite{srivastava2015unsupervised}{{5}{5.1}{section*.7}}}
\@writefile{brf}{\backcite{shi2017deep}{{5}{5.1}{section*.7}}}
\@writefile{brf}{\backcite{Finn2016Unsupervised}{{5}{5.1}{section*.7}}}
\@writefile{brf}{\backcite{de2016dynamic}{{5}{5.1}{section*.7}}}
\citation{wang2017predrnn}
\citation{wang2018predrnn++}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A comparison for predicting $10$ frames on the moving MNIST dataset. All of the models are trained with $10$ target frames and have comparable numbers of parameters.\relax }}{6}{table.caption.5}}
\newlabel{tab:mnist_10_result}{{1}{6}{A comparison for predicting $10$ frames on the moving MNIST dataset. All of the models are trained with $10$ target frames and have comparable numbers of parameters.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Ablation study of the MIM block with either stationary unit or non-stationary unit removed. These experiments also predict $10$ frames on the moving MNIST dataset.\relax }}{6}{table.caption.6}}
\newlabel{tab:mnist_10_result_self}{{2}{6}{Ablation study of the MIM block with either stationary unit or non-stationary unit removed. These experiments also predict $10$ frames on the moving MNIST dataset.\relax }{table.caption.6}{}}
\@writefile{brf}{\backcite{wang2017predrnn}{{6}{5.1}{section*.7}}}
\@writefile{brf}{\backcite{wang2018predrnn++}{{6}{5.1}{section*.7}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces A comparison for predicting $10$ frames on the moving MNIST dataset with acceleration. All of the models are also trained with $10$ target frames and have comparable numbers of parameters.\relax }}{6}{table.caption.8}}
\newlabel{tab:mnist_a_10_result_self}{{3}{6}{A comparison for predicting $10$ frames on the moving MNIST dataset with acceleration. All of the models are also trained with $10$ target frames and have comparable numbers of parameters.\relax }{table.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Frame-wise MSE over the MNIST test sets. Lower curves denote higher accuracy.\relax }}{6}{figure.caption.9}}
\newlabel{fig:mnist_mse}{{4}{6}{Frame-wise MSE over the MNIST test sets. Lower curves denote higher accuracy.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Frame-wise SSIM over the MNIST test sets. Higher curves denote higher accuracy.\relax }}{6}{figure.caption.10}}
\newlabel{fig:mnist_ssim}{{5}{6}{Frame-wise SSIM over the MNIST test sets. Higher curves denote higher accuracy.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A demonstration of predictions on moving MNIST test set. All models predict 10 frames into the future by observing 10 frames. Frames are shown at a two frames interval.\relax }}{6}{figure.caption.11}}
\newlabel{fig:mnist_results}{{6}{6}{A demonstration of predictions on moving MNIST test set. All models predict 10 frames into the future by observing 10 frames. Frames are shown at a two frames interval.\relax }{figure.caption.11}{}}
\citation{wang2017predrnn}
\citation{bengio2015scheduled}
\citation{Villegas2017Decomposing}
\citation{wang2018predrnn++}
\citation{wang2017predrnn}
\citation{wang2018predrnn++}
\citation{zhang2016dnn}
\citation{bengio2015scheduled}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}KTH Action Dataset}{7}{subsection.5.2}}
\@writefile{toc}{\contentsline {paragraph}{Implementation}{7}{section*.12}}
\@writefile{brf}{\backcite{wang2017predrnn}{{7}{5.2}{section*.12}}}
\@writefile{brf}{\backcite{bengio2015scheduled}{{7}{5.2}{section*.12}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces A comparison for predicting $20$ frames on the KTH action dataset. All of the models are trained with $10$ target frames and made to predict $20$ future frames at test time. They have comparable numbers of parameters.\relax }}{7}{table.caption.13}}
\newlabel{tab:kth_20_result}{{4}{7}{A comparison for predicting $20$ frames on the KTH action dataset. All of the models are trained with $10$ target frames and made to predict $20$ future frames at test time. They have comparable numbers of parameters.\relax }{table.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Percentage of value which greater than 0.9 from the forget gate (KTH dataset).\relax }}{7}{figure.caption.14}}
\newlabel{fig:action_forget}{{7}{7}{Percentage of value which greater than 0.9 from the forget gate (KTH dataset).\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{Results}{7}{section*.15}}
\@writefile{brf}{\backcite{Villegas2017Decomposing}{{7}{5.2}{section*.15}}}
\@writefile{brf}{\backcite{wang2018predrnn++}{{7}{5.2}{section*.15}}}
\@writefile{brf}{\backcite{wang2017predrnn}{{7}{5.2}{section*.15}}}
\@writefile{brf}{\backcite{wang2018predrnn++}{{7}{5.2}{section*.15}}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces A comparison for predicting $20$ frames on the "stationary" KTH action dataset. All of the models are also trained with $10$ target frames and made to predict $20$ future frames at test time.\relax }}{7}{table.caption.16}}
\newlabel{tab:KTH_s_20_result}{{5}{7}{A comparison for predicting $20$ frames on the "stationary" KTH action dataset. All of the models are also trained with $10$ target frames and made to predict $20$ future frames at test time.\relax }{table.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}TaxiBJ Dataset}{7}{subsection.5.3}}
\@writefile{toc}{\contentsline {paragraph}{Implementation}{7}{section*.19}}
\@writefile{brf}{\backcite{zhang2016dnn}{{7}{5.3}{section*.19}}}
\citation{zhang2017deep}
\bibstyle{ieee}
\bibdata{JZhang}
\bibcite{Abadi2016TensorFlow}{{1}{}{{}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces A comparison for predicting $20$ frames on the "non-stationary" KTH action dataset. All of the models are also trained with $10$ target frames and made to predict $20$ future frames at test time.\relax }}{8}{table.caption.17}}
\newlabel{tab:KTH_n_20_result}{{6}{8}{A comparison for predicting $20$ frames on the "non-stationary" KTH action dataset. All of the models are also trained with $10$ target frames and made to predict $20$ future frames at test time.\relax }{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A demonstration of predictions on KTH action test set. All models predict 20 frames into the future by observing 10 frames. Frames are shown at a three frames interval.\relax }}{8}{figure.caption.18}}
\newlabel{fig:action_results}{{8}{8}{A demonstration of predictions on KTH action test set. All models predict 20 frames into the future by observing 10 frames. Frames are shown at a three frames interval.\relax }{figure.caption.18}{}}
\@writefile{brf}{\backcite{bengio2015scheduled}{{8}{5.3}{section*.19}}}
\@writefile{toc}{\contentsline {paragraph}{Results}{8}{section*.20}}
\@writefile{brf}{\backcite{zhang2017deep}{{8}{5.3}{section*.20}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusions}{8}{section.6}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces A comparison of MSE for predicting $4$ frames on the TaxiBJ dataset. All of the models are trained with $4$ target frames and have comparable numbers of parameters\relax }}{8}{table.caption.21}}
\newlabel{tab:taxibj_4_result}{{7}{8}{A comparison of MSE for predicting $4$ frames on the TaxiBJ dataset. All of the models are trained with $4$ target frames and have comparable numbers of parameters\relax }{table.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A demonstration of predictions on TaxiBJ test set. We also visualize the difference between the predictions and the ground truth images for easy observation\relax }}{8}{figure.caption.22}}
\newlabel{fig:taxibj_results}{{9}{8}{A demonstration of predictions on TaxiBJ test set. We also visualize the difference between the predictions and the ground truth images for easy observation\relax }{figure.caption.22}{}}
\bibcite{Ba2016Layer}{{2}{}{{}}{{}}}
\bibcite{bengio2015scheduled}{{3}{}{{}}{{}}}
\bibcite{Cho2014On}{{4}{}{{}}{{}}}
\bibcite{de2016dynamic}{{5}{}{{}}{{}}}
\bibcite{denton2018stochastic}{{6}{}{{}}{{}}}
\bibcite{Denton2015Deep}{{7}{}{{}}{{}}}
\bibcite{Finn2016Unsupervised}{{8}{}{{}}{{}}}
\bibcite{Goodfellow2014Generative}{{9}{}{{}}{{}}}
\bibcite{hochreiter1997long}{{10}{}{{}}{{}}}
\bibcite{ioffe2015batch}{{11}{}{{}}{{}}}
\bibcite{Kalchbrenner2016Video}{{12}{}{{}}{{}}}
\bibcite{Kingma2014Adam}{{13}{}{{}}{{}}}
\bibcite{kingma2013auto}{{14}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{15}{}{{}}{{}}}
\bibcite{lee2018stochastic}{{16}{}{{}}{{}}}
\bibcite{Mathieu2015Deep}{{17}{}{{}}{{}}}
\bibcite{oliu2017folded}{{18}{}{{}}{{}}}
\bibcite{patraucean2015spatio}{{19}{}{{}}{{}}}
\bibcite{percival1993spectral}{{20}{}{{}}{{}}}
\bibcite{Ranzato2014Video}{{21}{}{{}}{{}}}
\bibcite{shi2015convolutional}{{22}{}{{}}{{}}}
\bibcite{shi2017deep}{{23}{}{{}}{{}}}
\bibcite{srivastava2015unsupervised}{{24}{}{{}}{{}}}
\bibcite{Sutskever2014Sequence}{{25}{}{{}}{{}}}
\bibcite{van2016conditional}{{26}{}{{}}{{}}}
\bibcite{Villegas2017Decomposing}{{27}{}{{}}{{}}}
\bibcite{vondrick2016generating}{{28}{}{{}}{{}}}
\bibcite{wang2018predrnn++}{{29}{}{{}}{{}}}
\bibcite{wang2017predrnn}{{30}{}{{}}{{}}}
\bibcite{Wang2004Image}{{31}{}{{}}{{}}}
\bibcite{zhang2017deep}{{32}{}{{}}{{}}}
\bibcite{zhang2016dnn}{{33}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
